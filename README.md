# 100Day-ML-Marathon
## 第二屆《機器學習百日馬拉松》練習
* D1： 資料分析與評估
* D2：EDA-1/讀取資料EDA: Data summary
* D3： 3-1如何新建一個 dataframe?3-2 如何讀取其他資料? (非 csv 的資料)
* D4： EDA: 欄位的資料類型介紹及處理
* D5： EDA資料分佈
* D6： EDA: Outlier 及處理
* D7： 常用的數值取代：中位數與分位數連續數值標準化
* D8： DataFrame operationData frame merge/常用的 DataFrame 操作
* D9： EDA: correlation/相關係數簡介
* D10：EDA from Correlation
* D11：EDA: 不同數值範圍間的特徵如何檢視/繪圖與樣式Kernel Density Estimation (KDE)
* D12：EDA: 把連續型變數離散化
* D13：程式實作 把連續型變數離散化
* D14：Subplots
* D15：Heatmap & Grid-plot
* D16：模型初體驗 Logistic Regression
* D17：特徵工程簡介
* D18：特徵類型
* D19：數值型特徵-補缺失值與標準化
* D20：數值型特徵 - 去除離群值
* D21：數值型特徵 - 去除偏態
* D22：類別型特徵 - 基礎處理
* D23：類別型特徵 - 均值編碼
* D24：類別型特徵 - 其他進階處理
* D25：時間型特徵
* D26：特徵組合 - 數值與數值組合
* D27：特徵組合 - 類別與數值組合
* D28：特徵選擇
* D29：特徵評估
* D30：分類型特徵優化 - 葉編碼
* D31：機器學習概論
* D32：機器學習-流程與步驟
* D33：機器如何學習?
* D34：訓練/測試集切分的概念
* D35：regression vs. classification
* D36：評估指標選定/evaluation metrics
* D37：regression model 介紹 - 線性迴歸/羅吉斯回歸
* D38：regression model 程式碼撰寫
* D39：regression model 介紹 - LASSO 回歸/ Ridge 回歸
* D40：regression model 程式碼撰寫
* D41：tree based model - 決策樹 (Decision Tree) 模型介紹
* D42：tree based model - 決策樹程式碼撰寫
* D43：tree based model - 隨機森林 (Random Forest) 介紹
* D44：tree based model - 隨機森林程式碼撰寫
* D45：tree based model - 梯度提升機 (Gradient Boosting Machine) 介紹
* D46：tree based model - 梯度提升機程式碼撰寫
* D47：超參數調整與優化
* D48：Kaggle 競賽平台介紹
* D49：集成方法 : 混合泛化(Blending)
* D50：集成方法 : 堆疊泛化(Stacking)
* D51-D53：Kaggle期中考
* D54：clustering 1 非監督式機器學習簡介
* D55：clustering 2 聚類算法
* D56：K-mean 觀察 : 使用輪廓分析
* D57：clustering 3 階層分群算法
* D58：階層分群法 觀察 : 使用 2D 樣版資料集
* D59：dimension reduction 1 降維方法-主成份分析
* D60：PCA 觀察 : 使用手寫辨識資料集.
* D61：dimension reduction 2 降維方法-T-SNE
* D62：t-sne 觀察 : 分群與流形還原
* D63：神經網路介紹
* D64：深度學習體驗 : 模型調整與學習曲線
* D65：深度學習體驗 : 啟動函數與正規化
* D66：Keras 安裝與介紹
* D67：Keras Dataset
* D68：Keras Sequential API
* D69：Keras Module API
* D70：Multi-layer Perception多層感知
* D71：損失函數
* D72：啟動函數
* D73：梯度下降Gradient Descent
* D74：Gradient Descent 數學原理
* D75：BackPropagation
* D76：優化器optimizers
* D77：訓練神經網路的細節與技巧 - Validation and overfit
* D78：訓練神經網路前的注意事項
* D79：訓練神經網路的細節與技巧 - Learning rate effect
* D80：[練習 Day] 優化器與學習率的組合與比較
* D81：訓練神經網路的細節與技巧 - Regularization
* D82：訓練神經網路的細節與技巧 - Dropout
* D83：訓練神經網路的細節與技巧 - Batch normalization
* D84：[練習 Day] 正規化/機移除/批次標準化的 組合與比較
* D85：訓練神經網路的細節與技巧 - 使用 callbacks 函數做 earlystop
