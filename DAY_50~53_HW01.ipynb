{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import date\n",
    "\n",
    "from sklearn.model_selection import KFold, train_test_split, StratifiedKFold, cross_val_score, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import SGDClassifier, LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import log_loss, roc_auc_score, auc, roc_curve\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "DATA_ROOT = \"data/ml100marathon-02-01\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 添加label 目標column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfoff = pd.read_csv(os.path.join(DATA_ROOT,'train_offline.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User_id</th>\n",
       "      <th>Merchant_id</th>\n",
       "      <th>Coupon_id</th>\n",
       "      <th>Discount_rate</th>\n",
       "      <th>Distance</th>\n",
       "      <th>Date_received</th>\n",
       "      <th>Date</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1439408</td>\n",
       "      <td>2632</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20160217.0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1439408</td>\n",
       "      <td>2632</td>\n",
       "      <td>8591.0</td>\n",
       "      <td>20:1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20160217.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1439408</td>\n",
       "      <td>2632</td>\n",
       "      <td>1078.0</td>\n",
       "      <td>20:1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20160319.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1832624</td>\n",
       "      <td>3381</td>\n",
       "      <td>7610.0</td>\n",
       "      <td>200:20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20160429.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2029232</td>\n",
       "      <td>3381</td>\n",
       "      <td>11951.0</td>\n",
       "      <td>200:20</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20160129.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2223968</td>\n",
       "      <td>3381</td>\n",
       "      <td>9776.0</td>\n",
       "      <td>10:5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>20160129.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>73611</td>\n",
       "      <td>2099</td>\n",
       "      <td>12034.0</td>\n",
       "      <td>100:10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20160207.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>163606</td>\n",
       "      <td>1569</td>\n",
       "      <td>5054.0</td>\n",
       "      <td>200:30</td>\n",
       "      <td>10.0</td>\n",
       "      <td>20160421.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3273056</td>\n",
       "      <td>4833</td>\n",
       "      <td>7802.0</td>\n",
       "      <td>200:20</td>\n",
       "      <td>10.0</td>\n",
       "      <td>20160130.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>94107</td>\n",
       "      <td>3381</td>\n",
       "      <td>7610.0</td>\n",
       "      <td>200:20</td>\n",
       "      <td>2.0</td>\n",
       "      <td>20160412.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   User_id  Merchant_id  Coupon_id Discount_rate  Distance  Date_received  \\\n",
       "0  1439408         2632        NaN           NaN       0.0            NaN   \n",
       "1  1439408         2632     8591.0          20:1       0.0     20160217.0   \n",
       "2  1439408         2632     1078.0          20:1       0.0     20160319.0   \n",
       "3  1832624         3381     7610.0        200:20       0.0     20160429.0   \n",
       "4  2029232         3381    11951.0        200:20       1.0     20160129.0   \n",
       "5  2223968         3381     9776.0          10:5       2.0     20160129.0   \n",
       "6    73611         2099    12034.0        100:10       NaN     20160207.0   \n",
       "7   163606         1569     5054.0        200:30      10.0     20160421.0   \n",
       "8  3273056         4833     7802.0        200:20      10.0     20160130.0   \n",
       "9    94107         3381     7610.0        200:20       2.0     20160412.0   \n",
       "\n",
       "         Date  label  \n",
       "0  20160217.0     -1  \n",
       "1         NaN      0  \n",
       "2         NaN      0  \n",
       "3         NaN      0  \n",
       "4         NaN      0  \n",
       "5         NaN      0  \n",
       "6         NaN      0  \n",
       "7         NaN      0  \n",
       "8         NaN      0  \n",
       "9         NaN      0  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Creat target label \n",
    "\"\"\"\n",
    "According to the definition, \n",
    "1) buy with coupon within (include) 15 days ==> 1\n",
    "2) buy with coupon but out of 15 days ==> 0\n",
    "3) buy without coupon ==> -1 (we don't care)\n",
    "\"\"\"\n",
    "def label(row):\n",
    "    if np.isnan(row['Date_received']):\n",
    "        return -1\n",
    "    if not np.isnan(row['Date']):\n",
    "        td = pd.to_datetime(row['Date'], format='%Y%m%d') -  pd.to_datetime(row['Date_received'], format='%Y%m%d')\n",
    "        if td <= pd.Timedelta(15, 'D'):\n",
    "            return 1\n",
    "    return 0\n",
    "\n",
    "dfoff[\"label\"] = dfoff.apply(label, axis=1)\n",
    "##output new train_offline csv\n",
    "dfoff.reset_index(drop=True, inplace=True)\n",
    "dfoff.to_csv(DATA_ROOT+\"/train_offline_label.csv\", index_label=False ) \n",
    "dfoff[\"label\"].value_counts()\n",
    "dfoff.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ===================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1160742, 8)\n",
      "(306313, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User_id</th>\n",
       "      <th>Merchant_id</th>\n",
       "      <th>Coupon_id</th>\n",
       "      <th>Discount_rate</th>\n",
       "      <th>Distance</th>\n",
       "      <th>Date_received</th>\n",
       "      <th>Date</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1439408</td>\n",
       "      <td>2632</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20160217.0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1439408</td>\n",
       "      <td>2632</td>\n",
       "      <td>8591.0</td>\n",
       "      <td>20:1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20160217.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1439408</td>\n",
       "      <td>2632</td>\n",
       "      <td>1078.0</td>\n",
       "      <td>20:1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20160319.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1832624</td>\n",
       "      <td>3381</td>\n",
       "      <td>7610.0</td>\n",
       "      <td>200:20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20160429.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2029232</td>\n",
       "      <td>3381</td>\n",
       "      <td>11951.0</td>\n",
       "      <td>200:20</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20160129.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2223968</td>\n",
       "      <td>3381</td>\n",
       "      <td>9776.0</td>\n",
       "      <td>10:5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>20160129.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>73611</td>\n",
       "      <td>2099</td>\n",
       "      <td>12034.0</td>\n",
       "      <td>100:10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20160207.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>163606</td>\n",
       "      <td>1569</td>\n",
       "      <td>5054.0</td>\n",
       "      <td>200:30</td>\n",
       "      <td>10.0</td>\n",
       "      <td>20160421.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3273056</td>\n",
       "      <td>4833</td>\n",
       "      <td>7802.0</td>\n",
       "      <td>200:20</td>\n",
       "      <td>10.0</td>\n",
       "      <td>20160130.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>94107</td>\n",
       "      <td>3381</td>\n",
       "      <td>7610.0</td>\n",
       "      <td>200:20</td>\n",
       "      <td>2.0</td>\n",
       "      <td>20160412.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   User_id  Merchant_id  Coupon_id Discount_rate  Distance  Date_received  \\\n",
       "0  1439408         2632        NaN           NaN       0.0            NaN   \n",
       "1  1439408         2632     8591.0          20:1       0.0     20160217.0   \n",
       "2  1439408         2632     1078.0          20:1       0.0     20160319.0   \n",
       "3  1832624         3381     7610.0        200:20       0.0     20160429.0   \n",
       "4  2029232         3381    11951.0        200:20       1.0     20160129.0   \n",
       "5  2223968         3381     9776.0          10:5       2.0     20160129.0   \n",
       "6    73611         2099    12034.0        100:10       NaN     20160207.0   \n",
       "7   163606         1569     5054.0        200:30      10.0     20160421.0   \n",
       "8  3273056         4833     7802.0        200:20      10.0     20160130.0   \n",
       "9    94107         3381     7610.0        200:20       2.0     20160412.0   \n",
       "\n",
       "         Date  label  \n",
       "0  20160217.0     -1  \n",
       "1         NaN      0  \n",
       "2         NaN      0  \n",
       "3         NaN      0  \n",
       "4         NaN      0  \n",
       "5         NaN      0  \n",
       "6         NaN      0  \n",
       "7         NaN      0  \n",
       "8         NaN      0  \n",
       "9         NaN      0  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfoff = pd.read_csv(os.path.join(DATA_ROOT,'train_offline_label.csv'))\n",
    "dftest = pd.read_csv(os.path.join(DATA_ROOT,'test_offline.csv'))\n",
    "dftest = dftest[~dftest.Coupon_id.isna()]\n",
    "dftest.reset_index(drop=True, inplace=False)\n",
    "print(dfoff.shape)\n",
    "print(dftest.shape)\n",
    "dfoff.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ====Generate feature===="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(306313, 10)\n"
     ]
    }
   ],
   "source": [
    "## coupon related feature\n",
    "\n",
    "def getDiscountType(row):\n",
    "    if row == 'null':\n",
    "        return 'null'\n",
    "    elif ':' in row:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def convertRate(row):\n",
    "    \"\"\"Convert discount to rate\"\"\"\n",
    "    if row == 'null':\n",
    "        return 1.0\n",
    "    elif ':' in row:\n",
    "        rows = row.split(':')\n",
    "        return 1.0 - float(rows[1])/float(rows[0])\n",
    "    else:\n",
    "        return float(row)\n",
    "\n",
    "def getDiscountMan(row):\n",
    "    if ':' in row:\n",
    "        rows = row.split(':')\n",
    "        return int(rows[0])\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def getDiscountJian(row):\n",
    "    if ':' in row:\n",
    "        rows = row.split(':')\n",
    "        return int(rows[1])\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def processData(df):\n",
    "    #f = df[df['label'] != -1].copy()\n",
    "    # convert discunt_rate\n",
    "    df['discount_rate'] = df['Discount_rate'].astype('str').apply(convertRate)\n",
    "    df['discount_man'] = df['Discount_rate'].astype('str').apply(getDiscountMan)\n",
    "    df['discount_jian'] = df['Discount_rate'].astype('str').apply(getDiscountJian)\n",
    "    df['discount_type'] = df['Discount_rate'].astype('str').apply(getDiscountType)\n",
    "    \n",
    "    \n",
    "\n",
    "    # convert distance\n",
    "    df.loc[df.Distance.isna(), \"Distance\"] = 99\n",
    "    \n",
    " \n",
    "    \n",
    "    return df\n",
    "\n",
    "dfoff = dfoff[dfoff['label'] != -1].copy()\n",
    "dfoff = processData(dfoff)\n",
    "dftest = processData(dftest)\n",
    "print(dftest.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## other feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  app.launch_new_instance()\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(746969, 19)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## dfoff\n",
    "\n",
    "t =  dfoff[['User_id']]\n",
    "t['this_month_user_receive_all_coupon_count'] = 1\n",
    "t = t.groupby('User_id').agg('sum').reset_index()\n",
    "\n",
    "    \n",
    "t1 = dfoff[['User_id','Coupon_id']]\n",
    "t1['this_month_user_receive_same_coupon_count'] = 1\n",
    "t1 = t1.groupby(['User_id','Coupon_id']).agg('sum').reset_index()\n",
    "dfoff = dfoff[~np.isnan(dfoff['Coupon_id'])].copy()\n",
    "#dftest['this_month_user_receive_all_coupon_count'].fillna(0)\n",
    "#dftest['this_month_user_receive_same_coupon_count'].fillna(0)\n",
    "\n",
    "t2 = dfoff[['User_id','Date_received']]\n",
    "t2['this_day_user_receive_all_coupon_count'] = 1\n",
    "t2 = t2.groupby(['User_id','Date_received']).agg('sum').reset_index()\n",
    "\n",
    "t3 = dfoff[['User_id','Coupon_id','Date_received']]\n",
    "t3['this_day_user_receive_same_coupon_count'] = 1\n",
    "t3 = t3.groupby(['User_id','Coupon_id','Date_received']).agg('sum').reset_index()\n",
    "\n",
    "t4 = dfoff[['User_id','Merchant_id','Coupon_id']]\n",
    "t4 = t4[~np.isnan(t4.Coupon_id)][['User_id','Merchant_id']]\n",
    "t4['user_merchant_received'] = 1\n",
    "t4 = t4.groupby(['User_id','Merchant_id']).agg('sum').reset_index()\n",
    "t4.drop_duplicates(inplace=True)\n",
    "\n",
    "t5 = dfoff[['User_id','Merchant_id']]\n",
    "t5['user_merchant_any'] = 1\n",
    "t5 = t5.groupby(['User_id','Merchant_id']).agg('sum').reset_index()\n",
    "t5.drop_duplicates(inplace=True)\n",
    "\n",
    "\n",
    "t6= dfoff[~np.isnan(dfoff.Coupon_id)][['Merchant_id']]\n",
    "t6['total_coupon'] = 1\n",
    "t6= t6.groupby('Merchant_id').agg('sum').reset_index()\n",
    "\n",
    "\n",
    "dfoff = pd.merge(dfoff,t,on='User_id',how='left')\n",
    "dfoff = pd.merge(dfoff,t1,on=['User_id','Coupon_id'],how='left')\n",
    "dfoff = pd.merge(dfoff,t2,on=['User_id','Date_received'],how='left')\n",
    "dfoff = pd.merge(dfoff,t3,on=['User_id','Coupon_id','Date_received'],how='left')\n",
    "dfoff = pd.merge(dfoff,t4,on=['User_id','Merchant_id'],how='left')\n",
    "dfoff = pd.merge(dfoff,t5,on=['User_id','Merchant_id'],how='left')\n",
    "dfoff = pd.merge(dfoff,t6,on=['Merchant_id'],how='left')\n",
    "\n",
    "dfoff.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(306313, 17)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##dftest\n",
    "## this_month_user_receive_all_coupon_count\n",
    "t =  dftest[['User_id']]\n",
    "t['this_month_user_receive_all_coupon_count'] = 1\n",
    "t = t.groupby('User_id').agg('sum').reset_index()\n",
    "\n",
    "    \n",
    "\n",
    "t1 = dftest[['User_id','Coupon_id']]\n",
    "t1['this_month_user_receive_same_coupon_count'] = 1\n",
    "t1 = t1.groupby(['User_id','Coupon_id']).agg('sum').reset_index()\n",
    "dftest = dftest[~np.isnan(dftest['Coupon_id'])].copy()\n",
    "#dftest['this_month_user_receive_all_coupon_count'].fillna(0)\n",
    "#dftest['this_month_user_receive_same_coupon_count'].fillna(0)\n",
    "dftest.head()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "t2 = dftest[['User_id','Date_received']]\n",
    "t2['this_day_user_receive_all_coupon_count'] = 1\n",
    "t2 = t2.groupby(['User_id','Date_received']).agg('sum').reset_index()\n",
    "\n",
    "t3 = dftest[['User_id','Coupon_id','Date_received']]\n",
    "t3['this_day_user_receive_same_coupon_count'] = 1\n",
    "t3 = t3.groupby(['User_id','Coupon_id','Date_received']).agg('sum').reset_index()\n",
    "\n",
    "\n",
    "t4 = dftest[['User_id','Merchant_id','Coupon_id']]\n",
    "t4 = t4[~np.isnan(t4.Coupon_id)][['User_id','Merchant_id']]\n",
    "t4['user_merchant_received'] = 1\n",
    "t4 = t4.groupby(['User_id','Merchant_id']).agg('sum').reset_index()\n",
    "t4.drop_duplicates(inplace=True)\n",
    "\n",
    "t5 = dftest[['User_id','Merchant_id']]\n",
    "t5['user_merchant_any'] = 1\n",
    "t5 = t5.groupby(['User_id','Merchant_id']).agg('sum').reset_index()\n",
    "t5.drop_duplicates(inplace=True)\n",
    "\n",
    "t6= dftest[~np.isnan(dftest.Coupon_id)][['Merchant_id']]\n",
    "t6['total_coupon'] = 1\n",
    "t6= t6.groupby('Merchant_id').agg('sum').reset_index()\n",
    "\n",
    "dftest = pd.merge(dftest,t,on='User_id',how='left')\n",
    "dftest = pd.merge(dftest,t1,on=['User_id','Coupon_id'],how='left')\n",
    "dftest = pd.merge(dftest,t2,on=['User_id','Date_received'],how='left')\n",
    "dftest = pd.merge(dftest,t3,on=['User_id','Coupon_id','Date_received'],how='left')\n",
    "dftest = pd.merge(dftest,t4,on=['User_id','Merchant_id'],how='left')\n",
    "dftest = pd.merge(dftest,t5,on=['User_id','Merchant_id'],how='left')\n",
    "dftest = pd.merge(dftest,t6,on=['Merchant_id'],how='left')\n",
    "\n",
    "dftest.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ======Split Data ======"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 662393, #positive: 32277\n",
      "Valid size: 84576, #positive: 4027\n"
     ]
    }
   ],
   "source": [
    "## Naive model\n",
    "def split_train_valid(row, date_cut=\"20160415\"):\n",
    "    is_train = True if pd.to_datetime(row, format=\"%Y%m%d\") < pd.to_datetime(date_cut, format=\"%Y%m%d\") else False\n",
    "    return is_train\n",
    "    \n",
    "df = dfoff[dfoff['label'] != -1].copy()\n",
    "#df = dfoff[dfoff['Date_received'] != 0].copy()\n",
    "df[\"is_train\"] = df[\"Date_received\"].apply(split_train_valid)\n",
    "train = df[df[\"is_train\"]]\n",
    "valid = df[~df[\"is_train\"]]\n",
    "train.reset_index(drop=True, inplace=True)\n",
    "train.to_csv(DATA_ROOT+\"/train.csv\", index_label=False ) \n",
    "valid.reset_index(drop=True, inplace=True)\n",
    "valid.to_csv(DATA_ROOT+\"/valid.csv\", index_label=False ) \n",
    "print(\"Train size: {}, #positive: {}\".format(len(train), train[\"label\"].sum()))\n",
    "print(\"Valid size: {}, #positive: {}\".format(len(valid), valid[\"label\"].sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12 ['discount_rate', 'discount_type', 'discount_man', 'discount_jian', 'Distance', 'this_month_user_receive_all_coupon_count', 'this_month_user_receive_same_coupon_count', 'this_day_user_receive_all_coupon_count', 'this_day_user_receive_same_coupon_count', 'user_merchant_received', 'user_merchant_any', 'total_coupon']\n"
     ]
    }
   ],
   "source": [
    "original_feature = ['discount_rate',\n",
    "                    'discount_type',\n",
    "                    'discount_man', \n",
    "                    'discount_jian',\n",
    "                    'Distance','this_month_user_receive_all_coupon_count','this_month_user_receive_same_coupon_count'\n",
    "                    ,'this_day_user_receive_all_coupon_count','this_day_user_receive_same_coupon_count',\n",
    "                    'user_merchant_received','user_merchant_any','total_coupon'\n",
    "                   ] \n",
    "predictors = original_feature\n",
    "print(len(original_feature),original_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "total_coupon                                 0.307353\n",
       "this_month_user_receive_all_coupon_count     0.154444\n",
       "Distance                                     0.100859\n",
       "this_month_user_receive_same_coupon_count    0.079483\n",
       "user_merchant_received                       0.069449\n",
       "this_day_user_receive_all_coupon_count       0.066814\n",
       "user_merchant_any                            0.060503\n",
       "discount_man                                 0.051546\n",
       "discount_rate                                0.048786\n",
       "discount_jian                                0.037826\n",
       "this_day_user_receive_same_coupon_count      0.020551\n",
       "discount_type                                0.002386\n",
       "dtype: float64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
    "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=1, min_samples_split=2,\n",
    "            min_weight_fraction_leaf=0.0, n_estimators='warn', n_jobs=None,\n",
    "            oob_score=False, random_state=None, verbose=0,\n",
    "            warm_start=False)\n",
    "rf.fit(train[predictors],train['label'].values)\n",
    "feats = pd.Series(data=rf.feature_importances_, index=train[predictors].columns)\n",
    "feats = feats.sort_values(ascending=False)\n",
    "feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.99501219, 0.00498781],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       ...,\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_predicted = rf.predict_proba(valid[predictors])\n",
    "rf_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation AUC: 0.724, Accuracy: 0.942\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "auc_score = roc_auc_score(y_true=valid.label, y_score=rf_predicted[:,1])\n",
    "acc = accuracy_score(y_true=valid.label, y_pred=rf_predicted.argmax(axis=1))\n",
    "print(\"Validation AUC: {:.3f}, Accuracy: {:.3f}\".format(auc_score, acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:334: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9505176316051269"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from sklearn.model_selection import cross_val_score\n",
    "MMEncoder = MinMaxScaler()\n",
    "train_X = MMEncoder.fit_transform(train[predictors])\n",
    "cross_val_score(estimator, train_X, train['label'].values, cv=5).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def check_model(data, predictors):\n",
    "    \n",
    "    classifier = lambda: SGDClassifier(\n",
    "        loss='log', \n",
    "        penalty='elasticnet', \n",
    "        fit_intercept=True, \n",
    "        max_iter=100, \n",
    "        shuffle=True, \n",
    "        n_jobs=1,\n",
    "        class_weight=None)\n",
    "\n",
    "    model = Pipeline(steps=[\n",
    "        ('ss', StandardScaler()),\n",
    "        ('en', classifier())\n",
    "    ])\n",
    "    \n",
    "    parameters = {\n",
    "        'en__alpha': [ 0.001, 0.01, 0.1],\n",
    "        'en__l1_ratio': [ 0.001, 0.01, 0.1]\n",
    "    }\n",
    "\n",
    "    folder = StratifiedKFold(n_splits=5, shuffle=True)\n",
    "    \n",
    "    grid_search = GridSearchCV(\n",
    "        model, \n",
    "        parameters, \n",
    "        cv=folder, \n",
    "        n_jobs=-1, \n",
    "        verbose=1)\n",
    "    grid_search = grid_search.fit(data[predictors], \n",
    "                                  data['label'])\n",
    "    \n",
    "    return grid_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
       "       early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
       "       l1_ratio=0.15, learning_rate='optimal', loss='log', max_iter=120,\n",
       "       n_iter=None, n_iter_no_change=5, n_jobs=1, penalty='elasticnet',\n",
       "       power_t=0.5, random_state=None, shuffle=True, tol=None,\n",
       "       validation_fraction=0.1, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model = check_model(train, predictors)\n",
    "model = SGDClassifier(\n",
    "        loss='log', \n",
    "        penalty='elasticnet', \n",
    "        fit_intercept=True, \n",
    "        max_iter=120, \n",
    "        shuffle=True, \n",
    "        n_jobs=1,\n",
    "        class_weight=None)\n",
    "model.fit(train[predictors],train['label'].values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_valid_pred = model.predict_proba(valid[predictors])\n",
    "valid1 = valid.copy()\n",
    "valid1['pred_prob'] = y_valid_pred[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation AUC: 0.724, Accuracy: 0.863\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "auc_score = roc_auc_score(y_true=valid.label, y_score=y_valid_pred[:,1])\n",
    "acc = accuracy_score(y_true=valid.label, y_pred=y_valid_pred.argmax(axis=1))\n",
    "print(\"Validation AUC: {:.3f}, Accuracy: {:.3f}\".format(auc_score, acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "train= train.drop(['Discount_rate'],axis=1)\n",
    "valid= valid.drop(['Discount_rate'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-0f54c3dad45f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcross_val_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_X\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'label'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'train_X' is not defined"
     ]
    }
   ],
   "source": [
    "cross_val_score(model, train_X, train['label'].values, cv=5).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv='warn', error_score='raise-deprecating',\n",
       "       estimator=XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bynode=1, colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
       "       max_delta_step=0, max_depth=3, min_child_weight=1, missing=None,\n",
       "       n_estimators=100, n_jobs=1, nthread=None,\n",
       "       objective='binary:logistic', random_state=0, reg_alpha=0,\n",
       "       reg_lambda=1, scale_pos_weight=1, seed=None, silent=None,\n",
       "       subsample=1, verbosity=1),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid={'max_depth': [3], 'n_estimators': [150]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='roc_auc', verbose=0)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from xgboost import  XGBClassifier\n",
    "xgb_model = XGBClassifier()\n",
    "parameters = {'max_depth': [3],'n_estimators':[150]}\n",
    "clf = GridSearchCV(xgb_model, parameters, scoring='roc_auc')\n",
    "clf.fit(train[predictors], train['label'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bynode=1, colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
       "       max_delta_step=0, max_depth=3, min_child_weight=1, missing=None,\n",
       "       n_estimators=700, n_jobs=1, nthread=None,\n",
       "       objective='binary:logistic', random_state=0, reg_alpha=0,\n",
       "       reg_lambda=1, scale_pos_weight=1, seed=None, silent=None,\n",
       "       subsample=1, verbosity=1)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from xgboost import  XGBClassifier\n",
    "xgb =XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
    "       colsample_bynode=1, colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
    "       max_delta_step=0, max_depth=3, min_child_weight=1, missing=None,\n",
    "       n_estimators=700, n_jobs=1, nthread=None, objective='binary:logistic',\n",
    "       random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
    "       seed=None, silent=None, subsample=1, verbosity=1)\n",
    "xgb.fit(train[predictors],train['label'].values.ravel())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_predicted = xgb.predict_proba(valid[predictors])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.9279875e-01, 7.2012534e-03],\n",
       "       [9.9957955e-01, 4.2042407e-04],\n",
       "       [9.9477619e-01, 5.2238065e-03],\n",
       "       ...,\n",
       "       [9.9925691e-01, 7.4309611e-04],\n",
       "       [9.3871045e-01, 6.1289560e-02],\n",
       "       [9.7702265e-01, 2.2977343e-02]], dtype=float32)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation AUC: 0.873, Accuracy: 0.955\n"
     ]
    }
   ],
   "source": [
    "auc_score = roc_auc_score(y_true=valid.label, y_score=xgb_predicted[:,1])\n",
    "acc = accuracy_score(y_true=valid.label, y_pred=xgb_predicted.argmax(axis=1))\n",
    "print(\"Validation AUC: {:.3f}, Accuracy: {:.3f}\".format(auc_score, acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User_id</th>\n",
       "      <th>Merchant_id</th>\n",
       "      <th>Coupon_id</th>\n",
       "      <th>Discount_rate</th>\n",
       "      <th>Distance</th>\n",
       "      <th>Date_received</th>\n",
       "      <th>discount_rate</th>\n",
       "      <th>discount_man</th>\n",
       "      <th>discount_jian</th>\n",
       "      <th>discount_type</th>\n",
       "      <th>this_month_user_receive_all_coupon_count</th>\n",
       "      <th>this_month_user_receive_same_coupon_count</th>\n",
       "      <th>this_day_user_receive_all_coupon_count</th>\n",
       "      <th>this_day_user_receive_same_coupon_count</th>\n",
       "      <th>user_merchant_received</th>\n",
       "      <th>user_merchant_any</th>\n",
       "      <th>total_coupon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1439408</td>\n",
       "      <td>4663</td>\n",
       "      <td>11002.0</td>\n",
       "      <td>150:20</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20160528.0</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>150</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>11312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1439408</td>\n",
       "      <td>2632</td>\n",
       "      <td>8591.0</td>\n",
       "      <td>20:1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20160613.0</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1439408</td>\n",
       "      <td>2632</td>\n",
       "      <td>8591.0</td>\n",
       "      <td>20:1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20160516.0</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2029232</td>\n",
       "      <td>450</td>\n",
       "      <td>1532.0</td>\n",
       "      <td>30:5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20160530.0</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>30</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>22210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2029232</td>\n",
       "      <td>6459</td>\n",
       "      <td>12737.0</td>\n",
       "      <td>20:1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20160519.0</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   User_id  Merchant_id  Coupon_id Discount_rate  Distance  Date_received  \\\n",
       "0  1439408         4663    11002.0        150:20       1.0     20160528.0   \n",
       "1  1439408         2632     8591.0          20:1       0.0     20160613.0   \n",
       "2  1439408         2632     8591.0          20:1       0.0     20160516.0   \n",
       "3  2029232          450     1532.0          30:5       0.0     20160530.0   \n",
       "4  2029232         6459    12737.0          20:1       0.0     20160519.0   \n",
       "\n",
       "   discount_rate  discount_man  discount_jian  discount_type  \\\n",
       "0       0.866667           150             20              1   \n",
       "1       0.950000            20              1              1   \n",
       "2       0.950000            20              1              1   \n",
       "3       0.833333            30              5              1   \n",
       "4       0.950000            20              1              1   \n",
       "\n",
       "   this_month_user_receive_all_coupon_count  \\\n",
       "0                                         3   \n",
       "1                                         3   \n",
       "2                                         3   \n",
       "3                                         2   \n",
       "4                                         2   \n",
       "\n",
       "   this_month_user_receive_same_coupon_count  \\\n",
       "0                                          1   \n",
       "1                                          2   \n",
       "2                                          2   \n",
       "3                                          1   \n",
       "4                                          1   \n",
       "\n",
       "   this_day_user_receive_all_coupon_count  \\\n",
       "0                                       1   \n",
       "1                                       1   \n",
       "2                                       1   \n",
       "3                                       1   \n",
       "4                                       1   \n",
       "\n",
       "   this_day_user_receive_same_coupon_count  user_merchant_received  \\\n",
       "0                                        1                       1   \n",
       "1                                        1                       2   \n",
       "2                                        1                       2   \n",
       "3                                        1                       1   \n",
       "4                                        1                       1   \n",
       "\n",
       "   user_merchant_any  total_coupon  \n",
       "0                  1         11312  \n",
       "1                  2            11  \n",
       "2                  2            11  \n",
       "3                  1         22210  \n",
       "4                  1            16  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dftest = dftest.fillna(0)\n",
    "dftest.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(306313, 17)\n",
      "(306313, 13)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "targetset = dftest.copy()\n",
    "print(targetset.shape)\n",
    "targetset = targetset[~targetset.Coupon_id.isna()]\n",
    "targetset.reset_index(drop=True, inplace=True)\n",
    "testset = targetset[predictors].copy()\n",
    "\n",
    "y_test_pred = model.predict_proba(testset[predictors])\n",
    "xgb_test_predicted = xgb.predict_proba(testset[predictors])\n",
    "rf_test_predicted = rf.predict_proba(testset[predictors])\n",
    "#stacking_test_predicted = stacking.predict_proba(testset[predictors])\n",
    "test1 = testset.copy()\n",
    "test1['pred_prob'] = xgb_test_predicted[:, 1]*0.9 + y_test_pred[:, 1]*0.06 +rf_test_predicted[:, 1]*0.04\n",
    "print(test1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(306313, 4)\n"
     ]
    }
   ],
   "source": [
    "output = pd.concat((targetset[[\"User_id\", \"Coupon_id\", \"Date_received\"]], test1[\"pred_prob\"]), axis=1)\n",
    "print(output.shape)\n",
    "\n",
    "output.loc[:, \"User_id\"] = output[\"User_id\"].apply(lambda x:str(int(x)))\n",
    "output.loc[:, \"Coupon_id\"] = output[\"Coupon_id\"].apply(lambda x:str(int(x)))\n",
    "output.loc[:, \"Date_received\"] = output[\"Date_received\"].apply(lambda x:str(int(x)))\n",
    "output[\"uid\"] = output[[\"User_id\", \"Coupon_id\", \"Date_received\"]].apply(lambda x: '_'.join(x.values), axis=1)\n",
    "output.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000020_2705_20160519</td>\n",
       "      <td>0.037732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000020_8192_20160513</td>\n",
       "      <td>0.077602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000065_1455_20160527</td>\n",
       "      <td>0.096831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000085_8067_20160513</td>\n",
       "      <td>0.193161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000086_2418_20160613</td>\n",
       "      <td>0.037360</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     uid     label\n",
       "0  1000020_2705_20160519  0.037732\n",
       "1  1000020_8192_20160513  0.077602\n",
       "2  1000065_1455_20160527  0.096831\n",
       "3  1000085_8067_20160513  0.193161\n",
       "4  1000086_2418_20160613  0.037360"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### NOTE: YOUR SUBMITION FILE SHOULD HAVE COLUMN NAME: uid, label\n",
    "out = output.groupby(\"uid\", as_index=False).mean()\n",
    "out = out[[\"uid\", \"pred_prob\"]]\n",
    "out.columns = [\"uid\", \"label\"]\n",
    "out.to_csv(\"baseline_example0616-9.csv\", header=[\"uid\", \"label\"], index=False) # submission format\n",
    "out.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
